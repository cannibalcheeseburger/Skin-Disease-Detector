{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "tensorflow",
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#limit memory\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1*X GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024*4))])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Xception model\n",
    "base_model = tf.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=\"xception_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "    input_shape=(256, 256, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 \n__________________________________________________________________________________________________\nblock5_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv2_act (Activation (None, 16, 16, 728)  0           block5_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock5_sepconv3_act (Activation (None, 16, 16, 728)  0           block5_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock5_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block5_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock5_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block5_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 16, 16, 728)  0           block5_sepconv3_bn[0][0]         \n                                                                 add_2[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1_act (Activation (None, 16, 16, 728)  0           add_3[0][0]                      \n__________________________________________________________________________________________________\nblock6_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv2_act (Activation (None, 16, 16, 728)  0           block6_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock6_sepconv3_act (Activation (None, 16, 16, 728)  0           block6_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock6_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block6_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock6_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block6_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 16, 16, 728)  0           block6_sepconv3_bn[0][0]         \n                                                                 add_3[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1_act (Activation (None, 16, 16, 728)  0           add_4[0][0]                      \n__________________________________________________________________________________________________\nblock7_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv2_act (Activation (None, 16, 16, 728)  0           block7_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock7_sepconv3_act (Activation (None, 16, 16, 728)  0           block7_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock7_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block7_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock7_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block7_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 16, 16, 728)  0           block7_sepconv3_bn[0][0]         \n                                                                 add_4[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1_act (Activation (None, 16, 16, 728)  0           add_5[0][0]                      \n__________________________________________________________________________________________________\nblock8_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv2_act (Activation (None, 16, 16, 728)  0           block8_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock8_sepconv3_act (Activation (None, 16, 16, 728)  0           block8_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock8_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block8_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock8_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block8_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 16, 16, 728)  0           block8_sepconv3_bn[0][0]         \n                                                                 add_5[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1_act (Activation (None, 16, 16, 728)  0           add_6[0][0]                      \n__________________________________________________________________________________________________\nblock9_sepconv1 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv1_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv1_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv1[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv2_act (Activation (None, 16, 16, 728)  0           block9_sepconv1_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv2 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv2_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv2_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv2[0][0]            \n__________________________________________________________________________________________________\nblock9_sepconv3_act (Activation (None, 16, 16, 728)  0           block9_sepconv2_bn[0][0]         \n__________________________________________________________________________________________________\nblock9_sepconv3 (SeparableConv2 (None, 16, 16, 728)  536536      block9_sepconv3_act[0][0]        \n__________________________________________________________________________________________________\nblock9_sepconv3_bn (BatchNormal (None, 16, 16, 728)  2912        block9_sepconv3[0][0]            \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 16, 16, 728)  0           block9_sepconv3_bn[0][0]         \n                                                                 add_6[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_7[0][0]                      \n__________________________________________________________________________________________________\nblock10_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv2_act (Activatio (None, 16, 16, 728)  0           block10_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock10_sepconv3_act (Activatio (None, 16, 16, 728)  0           block10_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock10_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block10_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock10_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block10_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 16, 16, 728)  0           block10_sepconv3_bn[0][0]        \n                                                                 add_7[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_8[0][0]                      \n__________________________________________________________________________________________________\nblock11_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv2_act (Activatio (None, 16, 16, 728)  0           block11_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock11_sepconv3_act (Activatio (None, 16, 16, 728)  0           block11_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock11_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block11_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock11_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block11_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 16, 16, 728)  0           block11_sepconv3_bn[0][0]        \n                                                                 add_8[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_9[0][0]                      \n__________________________________________________________________________________________________\nblock12_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv2_act (Activatio (None, 16, 16, 728)  0           block12_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv2 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv2_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock12_sepconv3_act (Activatio (None, 16, 16, 728)  0           block12_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nblock12_sepconv3 (SeparableConv (None, 16, 16, 728)  536536      block12_sepconv3_act[0][0]       \n__________________________________________________________________________________________________\nblock12_sepconv3_bn (BatchNorma (None, 16, 16, 728)  2912        block12_sepconv3[0][0]           \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 16, 16, 728)  0           block12_sepconv3_bn[0][0]        \n                                                                 add_9[0][0]                      \n__________________________________________________________________________________________________\nblock13_sepconv1_act (Activatio (None, 16, 16, 728)  0           add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_sepconv1 (SeparableConv (None, 16, 16, 728)  536536      block13_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv1_bn (BatchNorma (None, 16, 16, 728)  2912        block13_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock13_sepconv2_act (Activatio (None, 16, 16, 728)  0           block13_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock13_sepconv2 (SeparableConv (None, 16, 16, 1024) 752024      block13_sepconv2_act[0][0]       \n__________________________________________________________________________________________________\nblock13_sepconv2_bn (BatchNorma (None, 16, 16, 1024) 4096        block13_sepconv2[0][0]           \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 8, 8, 1024)   745472      add_10[0][0]                     \n__________________________________________________________________________________________________\nblock13_pool (MaxPooling2D)     (None, 8, 8, 1024)   0           block13_sepconv2_bn[0][0]        \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 8, 8, 1024)   4096        conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 8, 8, 1024)   0           block13_pool[0][0]               \n                                                                 batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nblock14_sepconv1 (SeparableConv (None, 8, 8, 1536)   1582080     add_11[0][0]                     \n__________________________________________________________________________________________________\nblock14_sepconv1_bn (BatchNorma (None, 8, 8, 1536)   6144        block14_sepconv1[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv1_act (Activatio (None, 8, 8, 1536)   0           block14_sepconv1_bn[0][0]        \n__________________________________________________________________________________________________\nblock14_sepconv2 (SeparableConv (None, 8, 8, 2048)   3159552     block14_sepconv1_act[0][0]       \n__________________________________________________________________________________________________\nblock14_sepconv2_bn (BatchNorma (None, 8, 8, 2048)   8192        block14_sepconv2[0][0]           \n__________________________________________________________________________________________________\nblock14_sepconv2_act (Activatio (None, 8, 8, 2048)   0           block14_sepconv2_bn[0][0]        \n==================================================================================================\nTotal params: 20,861,480\nTrainable params: 20,806,952\nNon-trainable params: 54,528\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary of the model\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making layers of base model untrainable so that their weights won't change during training for first few epochs\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the input and output layers of the base model\n",
    "base_input = base_model.layers[0].input\n",
    "base_output = base_model.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layers to the base model\n",
    "l1 = Flatten()(base_output)\n",
    "l2 = Dense(512, activation='elu')(l1)\n",
    "l3 = Dropout(0.2)(l2)\n",
    "l4 = Dense(256, activation='elu')(l3)\n",
    "l5 = Dropout(0.2)(l4)\n",
    "l6 = Dense(12, activation='softmax')(l5)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_input, outputs=l6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1740 images belonging to 12 classes.\nFound 443 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "#Importing the data and augmenting it:\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.15,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'Dataset/OG_Train',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=69,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "        'Dataset/OG_Valid',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=17,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model i.e selecting the optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 25 steps, validate for 27 steps\n",
      "Epoch 1/10\n",
      "11/25 [============>.................] - ETA: 19s - loss: 22.8741 - acc: 0.1507WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-99ab08cf9783>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stoping_cb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m       verbose=1)\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training the model for few epoch so that the weights of pretrained layers don't change abruptly\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=25,\n",
    "      validation_data=(valid_generator), \n",
    "      callbacks=[checkpoint_cb, early_stoping_cb], \n",
    "      epochs=10,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making some layers of base model trainable \n",
    "for layer in base_model.layers[-6:-1]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the callbacks\n",
    "\n",
    "# checkpoint_cb will save the model which will perform the best on validation set\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "\n",
    "# early_stoping_cb will stop the model traning once it stops improving\n",
    "early_stoping_cb = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model i.e selecting the optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics = ['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 10 steps, validate for 27 steps\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 8.7608 - categorical_accuracy: 0.1934 - val_loss: 5.7067 - val_categorical_accuracy: 0.2144\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 15s 2s/step - loss: 6.3289 - categorical_accuracy: 0.2296 - val_loss: 3.9695 - val_categorical_accuracy: 0.2460\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 16s 2s/step - loss: 4.9402 - categorical_accuracy: 0.2783 - val_loss: 4.0524 - val_categorical_accuracy: 0.2460\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 3.9685 - categorical_accuracy: 0.3232 - val_loss: 4.4405 - val_categorical_accuracy: 0.2393\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 28s 3s/step - loss: 3.2996 - categorical_accuracy: 0.3435 - val_loss: 3.1676 - val_categorical_accuracy: 0.3002\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 2.8691 - categorical_accuracy: 0.3616 - val_loss: 3.6192 - val_categorical_accuracy: 0.2889\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 16s 2s/step - loss: 2.5335 - categorical_accuracy: 0.3928 - val_loss: 3.9703 - val_categorical_accuracy: 0.2664\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 17s 2s/step - loss: 2.1078 - categorical_accuracy: 0.4119 - val_loss: 3.1357 - val_categorical_accuracy: 0.3228\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 21s 2s/step - loss: 1.8359 - categorical_accuracy: 0.4623 - val_loss: 3.1549 - val_categorical_accuracy: 0.3138\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 23s 2s/step - loss: 1.8507 - categorical_accuracy: 0.4434 - val_loss: 3.1441 - val_categorical_accuracy: 0.3318\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 24s 2s/step - loss: 1.7424 - categorical_accuracy: 0.4667 - val_loss: 2.9543 - val_categorical_accuracy: 0.3499\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 20s 2s/step - loss: 1.7326 - categorical_accuracy: 0.4733 - val_loss: 3.2989 - val_categorical_accuracy: 0.3115\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 22s 2s/step - loss: 1.5674 - categorical_accuracy: 0.4913 - val_loss: 3.5124 - val_categorical_accuracy: 0.2980\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 19s 2s/step - loss: 1.3867 - categorical_accuracy: 0.5159 - val_loss: 2.9067 - val_categorical_accuracy: 0.3476\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 16s 2s/step - loss: 1.3926 - categorical_accuracy: 0.5330 - val_loss: 2.9569 - val_categorical_accuracy: 0.3341\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 15s 2s/step - loss: 1.3941 - categorical_accuracy: 0.5550 - val_loss: 3.2205 - val_categorical_accuracy: 0.3070\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 18s 2s/step - loss: 1.3179 - categorical_accuracy: 0.5768 - val_loss: 3.0867 - val_categorical_accuracy: 0.3160\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 15s 2s/step - loss: 1.3589 - categorical_accuracy: 0.5551 - val_loss: 2.6492 - val_categorical_accuracy: 0.3431\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.2776 - categorical_accuracy: 0.5566 - val_loss: 2.9779 - val_categorical_accuracy: 0.3363\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 15s 1s/step - loss: 1.3481 - categorical_accuracy: 0.5739 - val_loss: 2.8705 - val_categorical_accuracy: 0.3431\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.1374 - categorical_accuracy: 0.6148 - val_loss: 3.1318 - val_categorical_accuracy: 0.3318\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.1350 - categorical_accuracy: 0.6321 - val_loss: 3.0514 - val_categorical_accuracy: 0.3409\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 15s 1s/step - loss: 1.1778 - categorical_accuracy: 0.6261 - val_loss: 2.8976 - val_categorical_accuracy: 0.3454\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.1327 - categorical_accuracy: 0.6058 - val_loss: 2.9794 - val_categorical_accuracy: 0.3409\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 1.0510 - categorical_accuracy: 0.6305 - val_loss: 3.0325 - val_categorical_accuracy: 0.3341\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.9986 - categorical_accuracy: 0.6609 - val_loss: 3.1233 - val_categorical_accuracy: 0.3386\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.9931 - categorical_accuracy: 0.6696 - val_loss: 3.3801 - val_categorical_accuracy: 0.3093\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.9263 - categorical_accuracy: 0.6714 - val_loss: 3.6059 - val_categorical_accuracy: 0.3251\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 1.0259 - categorical_accuracy: 0.6768 - val_loss: 3.1945 - val_categorical_accuracy: 0.3386\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.8794 - categorical_accuracy: 0.7029 - val_loss: 3.3795 - val_categorical_accuracy: 0.3070\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.9781 - categorical_accuracy: 0.6783 - val_loss: 3.2387 - val_categorical_accuracy: 0.3363\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.9615 - categorical_accuracy: 0.6725 - val_loss: 3.1246 - val_categorical_accuracy: 0.3386\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.8664 - categorical_accuracy: 0.7203 - val_loss: 3.2788 - val_categorical_accuracy: 0.3363\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.7759 - categorical_accuracy: 0.7280 - val_loss: 3.1998 - val_categorical_accuracy: 0.3363\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.8121 - categorical_accuracy: 0.7203 - val_loss: 3.3730 - val_categorical_accuracy: 0.3251\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.7136 - categorical_accuracy: 0.7673 - val_loss: 3.5467 - val_categorical_accuracy: 0.3047\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.7080 - categorical_accuracy: 0.7720 - val_loss: 2.9348 - val_categorical_accuracy: 0.3567\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.7849 - categorical_accuracy: 0.7333 - val_loss: 3.3314 - val_categorical_accuracy: 0.3205\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6894 - categorical_accuracy: 0.7704 - val_loss: 3.1705 - val_categorical_accuracy: 0.3454\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.7566 - categorical_accuracy: 0.7609 - val_loss: 3.3362 - val_categorical_accuracy: 0.3251\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.7644 - categorical_accuracy: 0.7464 - val_loss: 3.3813 - val_categorical_accuracy: 0.3409\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.7158 - categorical_accuracy: 0.7725 - val_loss: 2.8525 - val_categorical_accuracy: 0.3905\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5577 - categorical_accuracy: 0.8176 - val_loss: 3.1444 - val_categorical_accuracy: 0.3612\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.6870 - categorical_accuracy: 0.7768 - val_loss: 3.2743 - val_categorical_accuracy: 0.3521\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5065 - categorical_accuracy: 0.8223 - val_loss: 3.0668 - val_categorical_accuracy: 0.3815\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.7027 - categorical_accuracy: 0.7696 - val_loss: 3.8051 - val_categorical_accuracy: 0.3138\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.6185 - categorical_accuracy: 0.7899 - val_loss: 3.5608 - val_categorical_accuracy: 0.3612\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.5747 - categorical_accuracy: 0.8087 - val_loss: 3.4613 - val_categorical_accuracy: 0.3431\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.5545 - categorical_accuracy: 0.8116 - val_loss: 3.4694 - val_categorical_accuracy: 0.3363\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5280 - categorical_accuracy: 0.8208 - val_loss: 3.4206 - val_categorical_accuracy: 0.3612\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.5460 - categorical_accuracy: 0.8246 - val_loss: 3.3054 - val_categorical_accuracy: 0.3567\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.5337 - categorical_accuracy: 0.8261 - val_loss: 3.3301 - val_categorical_accuracy: 0.3454\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4371 - categorical_accuracy: 0.8506 - val_loss: 3.1750 - val_categorical_accuracy: 0.3747\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.5035 - categorical_accuracy: 0.8275 - val_loss: 3.1685 - val_categorical_accuracy: 0.3792\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.5015 - categorical_accuracy: 0.8192 - val_loss: 3.2403 - val_categorical_accuracy: 0.3725\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.4284 - categorical_accuracy: 0.8696 - val_loss: 3.5321 - val_categorical_accuracy: 0.3454\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.4855 - categorical_accuracy: 0.8478 - val_loss: 3.5235 - val_categorical_accuracy: 0.3747\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.4690 - categorical_accuracy: 0.8319 - val_loss: 3.0320 - val_categorical_accuracy: 0.3905\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4444 - categorical_accuracy: 0.8522 - val_loss: 3.1689 - val_categorical_accuracy: 0.3837\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3485 - categorical_accuracy: 0.8855 - val_loss: 3.2004 - val_categorical_accuracy: 0.3725\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3857 - categorical_accuracy: 0.8710 - val_loss: 3.5434 - val_categorical_accuracy: 0.3657\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.4152 - categorical_accuracy: 0.8652 - val_loss: 3.4372 - val_categorical_accuracy: 0.3612\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.4272 - categorical_accuracy: 0.8711 - val_loss: 3.5294 - val_categorical_accuracy: 0.3702\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3544 - categorical_accuracy: 0.8826 - val_loss: 3.5342 - val_categorical_accuracy: 0.3612\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3055 - categorical_accuracy: 0.8836 - val_loss: 3.5586 - val_categorical_accuracy: 0.3837\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3745 - categorical_accuracy: 0.8768 - val_loss: 3.6852 - val_categorical_accuracy: 0.3792\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3045 - categorical_accuracy: 0.8962 - val_loss: 3.5820 - val_categorical_accuracy: 0.3815\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3981 - categorical_accuracy: 0.8739 - val_loss: 4.0966 - val_categorical_accuracy: 0.3860\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3250 - categorical_accuracy: 0.8826 - val_loss: 4.1153 - val_categorical_accuracy: 0.3792\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.3791 - categorical_accuracy: 0.8739 - val_loss: 4.0405 - val_categorical_accuracy: 0.3815\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2457 - categorical_accuracy: 0.9182 - val_loss: 4.1138 - val_categorical_accuracy: 0.3476\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3275 - categorical_accuracy: 0.8899 - val_loss: 3.4824 - val_categorical_accuracy: 0.3995\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3328 - categorical_accuracy: 0.8884 - val_loss: 3.7336 - val_categorical_accuracy: 0.3679\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3248 - categorical_accuracy: 0.8868 - val_loss: 3.9854 - val_categorical_accuracy: 0.3544\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.3021 - categorical_accuracy: 0.8821 - val_loss: 4.0727 - val_categorical_accuracy: 0.3476\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2777 - categorical_accuracy: 0.9087 - val_loss: 4.1228 - val_categorical_accuracy: 0.3612\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.3101 - categorical_accuracy: 0.8971 - val_loss: 4.5236 - val_categorical_accuracy: 0.3183\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2873 - categorical_accuracy: 0.9119 - val_loss: 4.1866 - val_categorical_accuracy: 0.3318\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2659 - categorical_accuracy: 0.9072 - val_loss: 3.9452 - val_categorical_accuracy: 0.3657\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2885 - categorical_accuracy: 0.8957 - val_loss: 4.3084 - val_categorical_accuracy: 0.3386\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2541 - categorical_accuracy: 0.9087 - val_loss: 4.0822 - val_categorical_accuracy: 0.3567\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 15s 1s/step - loss: 0.2421 - categorical_accuracy: 0.9174 - val_loss: 4.3046 - val_categorical_accuracy: 0.3521\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2642 - categorical_accuracy: 0.9145 - val_loss: 4.1131 - val_categorical_accuracy: 0.3679\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.2468 - categorical_accuracy: 0.9246 - val_loss: 4.0319 - val_categorical_accuracy: 0.3725\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2302 - categorical_accuracy: 0.9174 - val_loss: 4.4447 - val_categorical_accuracy: 0.3612\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2175 - categorical_accuracy: 0.9261 - val_loss: 4.5106 - val_categorical_accuracy: 0.3747\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2424 - categorical_accuracy: 0.9304 - val_loss: 4.4050 - val_categorical_accuracy: 0.3702\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2511 - categorical_accuracy: 0.9232 - val_loss: 4.7314 - val_categorical_accuracy: 0.3363\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1779 - categorical_accuracy: 0.9435 - val_loss: 4.5913 - val_categorical_accuracy: 0.3454\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1556 - categorical_accuracy: 0.9481 - val_loss: 4.2605 - val_categorical_accuracy: 0.3679\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2250 - categorical_accuracy: 0.9290 - val_loss: 4.5604 - val_categorical_accuracy: 0.3499\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2029 - categorical_accuracy: 0.9261 - val_loss: 5.2776 - val_categorical_accuracy: 0.3318\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.1949 - categorical_accuracy: 0.9403 - val_loss: 4.9307 - val_categorical_accuracy: 0.3386\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2871 - categorical_accuracy: 0.9029 - val_loss: 4.2087 - val_categorical_accuracy: 0.3837\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.2494 - categorical_accuracy: 0.9009 - val_loss: 4.7228 - val_categorical_accuracy: 0.3567\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.1535 - categorical_accuracy: 0.9465 - val_loss: 4.3487 - val_categorical_accuracy: 0.3612\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.2084 - categorical_accuracy: 0.9174 - val_loss: 4.6326 - val_categorical_accuracy: 0.3544\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1663 - categorical_accuracy: 0.9449 - val_loss: 5.0189 - val_categorical_accuracy: 0.3363\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 15s 2s/step - loss: 0.2114 - categorical_accuracy: 0.9217 - val_loss: 4.1383 - val_categorical_accuracy: 0.3928\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 14s 1s/step - loss: 0.1709 - categorical_accuracy: 0.9420 - val_loss: 4.5256 - val_categorical_accuracy: 0.3612\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=10,\n",
    "      validation_data=(valid_generator),  \n",
    "      epochs=100,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"252.317344pt\" version=\"1.1\" viewBox=\"0 0 372.103125 252.317344\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-01-30T04:47:51.515154</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 252.317344 \r\nL 372.103125 252.317344 \r\nL 372.103125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 30.103125 228.439219 \r\nL 364.903125 228.439219 \r\nL 364.903125 10.999219 \r\nL 30.103125 10.999219 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m6f34c25ead\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m6f34c25ead\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(42.140057 243.037656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"106.80891\" xlink:href=\"#m6f34c25ead\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(100.44641 243.037656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"168.296513\" xlink:href=\"#m6f34c25ead\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(161.934013 243.037656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"229.784117\" xlink:href=\"#m6f34c25ead\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 60 -->\r\n      <g transform=\"translate(223.421617 243.037656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"291.27172\" xlink:href=\"#m6f34c25ead\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 80 -->\r\n      <g transform=\"translate(284.90922 243.037656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.759323\" xlink:href=\"#m6f34c25ead\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(343.215573 243.037656)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m997a6832d5\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m997a6832d5\" y=\"228.439219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(7.2 232.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m997a6832d5\" y=\"184.951219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.2 -->\r\n      <g transform=\"translate(7.2 188.750437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m997a6832d5\" y=\"141.463219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.4 -->\r\n      <g transform=\"translate(7.2 145.262437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m997a6832d5\" y=\"97.975219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.6 -->\r\n      <g transform=\"translate(7.2 101.774437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m997a6832d5\" y=\"54.487219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.8 -->\r\n      <g transform=\"translate(7.2 58.286437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m997a6832d5\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p831cd925e8)\" d=\"M 120.506402 -1 \r\nL 122.180811 11.29545 \r\nL 125.255191 12.489207 \r\nL 128.329571 16.901883 \r\nL 131.403951 5.376668 \r\nL 134.478332 37.226955 \r\nL 137.552712 15.760026 \r\nL 140.627092 19.371936 \r\nL 143.701472 40.049542 \r\nL 146.775852 52.283525 \r\nL 149.850232 51.854012 \r\nL 152.924613 65.193897 \r\nL 155.998993 64.186434 \r\nL 159.073373 57.774558 \r\nL 162.147753 74.555089 \r\nL 165.222133 63.925398 \r\nL 168.296513 62.235122 \r\nL 171.370894 72.787218 \r\nL 174.445274 100.442997 \r\nL 177.519654 79.047605 \r\nL 180.594034 113.417281 \r\nL 183.668414 75.649116 \r\nL 186.742794 93.948041 \r\nL 189.817175 103.476431 \r\nL 192.891555 107.874709 \r\nL 195.965935 108.335692 \r\nL 199.040315 109.724786 \r\nL 202.114695 112.38441 \r\nL 205.189075 127.85701 \r\nL 208.263456 118.953404 \r\nL 211.337836 111.671867 \r\nL 214.412216 135.29041 \r\nL 217.486596 122.882171 \r\nL 220.560976 126.462942 \r\nL 223.635356 126.049711 \r\nL 226.709737 152.657982 \r\nL 229.784117 144.571955 \r\nL 232.858497 138.160272 \r\nL 235.932877 131.226852 \r\nL 239.007257 151.378313 \r\nL 242.081637 157.698999 \r\nL 245.156018 146.99834 \r\nL 248.230398 157.335333 \r\nL 251.304778 141.887037 \r\nL 254.379158 157.766453 \r\nL 257.453538 145.998901 \r\nL 260.527918 173.297439 \r\nL 263.602299 153.870047 \r\nL 266.676679 156.071732 \r\nL 269.751059 156.200642 \r\nL 272.825439 158.038771 \r\nL 275.899819 168.058601 \r\nL 278.974199 161.020436 \r\nL 282.04858 165.045337 \r\nL 285.12296 170.617389 \r\nL 288.19734 165.715242 \r\nL 291.27172 173.176858 \r\nL 294.3461 175.80229 \r\nL 297.42048 170.994166 \r\nL 300.494861 174.773745 \r\nL 303.569241 178.378775 \r\nL 306.643621 181.138078 \r\nL 309.718001 175.732037 \r\nL 312.792381 173.834478 \r\nL 315.866761 189.757164 \r\nL 318.941142 192.275902 \r\nL 322.015522 179.520938 \r\nL 325.089902 181.090022 \r\nL 328.164282 182.822256 \r\nL 331.238662 166.008347 \r\nL 334.313042 171.341329 \r\nL 337.387423 192.660897 \r\nL 340.461803 183.116751 \r\nL 343.536183 192.284955 \r\nL 346.610563 182.479041 \r\nL 349.684943 191.28246 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p831cd925e8)\" d=\"M 45.321307 186.387143 \r\nL 48.395687 178.523747 \r\nL 51.470067 167.934178 \r\nL 54.544447 158.165134 \r\nL 57.618827 153.753305 \r\nL 60.693208 149.805259 \r\nL 63.767588 143.038869 \r\nL 66.841968 138.864877 \r\nL 69.916348 127.924502 \r\nL 72.990728 132.02714 \r\nL 76.065108 126.967218 \r\nL 79.139489 125.531293 \r\nL 82.213869 121.610003 \r\nL 85.288249 116.252782 \r\nL 88.362629 112.539592 \r\nL 91.437009 107.753187 \r\nL 94.511389 103.017302 \r\nL 97.58577 107.744257 \r\nL 100.66015 107.411291 \r\nL 103.73453 103.647568 \r\nL 106.80891 94.76148 \r\nL 109.88329 91.000725 \r\nL 112.95767 92.302872 \r\nL 116.032051 96.714695 \r\nL 119.106431 91.342621 \r\nL 122.180811 84.739746 \r\nL 125.255191 82.848961 \r\nL 128.329571 82.453565 \r\nL 131.403951 81.27331 \r\nL 134.478332 75.600955 \r\nL 137.552712 80.958177 \r\nL 140.627092 82.218696 \r\nL 143.701472 71.819399 \r\nL 146.775852 70.145637 \r\nL 149.850232 71.819399 \r\nL 152.924613 61.598464 \r\nL 155.998993 60.572801 \r\nL 159.073373 68.983215 \r\nL 162.147753 60.914684 \r\nL 165.222133 62.995741 \r\nL 168.296513 66.147045 \r\nL 171.370894 60.474703 \r\nL 174.445274 50.658082 \r\nL 177.519654 59.529305 \r\nL 180.594034 49.632432 \r\nL 183.668414 61.104956 \r\nL 186.742794 56.693134 \r\nL 189.817175 52.596431 \r\nL 192.891555 51.966178 \r\nL 195.965935 49.974315 \r\nL 199.040315 49.130008 \r\nL 202.114695 48.814875 \r\nL 205.189075 43.478468 \r\nL 208.263456 48.499742 \r\nL 211.337836 50.316199 \r\nL 214.412216 39.360964 \r\nL 217.486596 44.087919 \r\nL 220.560976 47.554343 \r\nL 223.635356 43.136572 \r\nL 226.709737 35.894528 \r\nL 229.784117 39.045831 \r\nL 232.858497 40.30635 \r\nL 235.932877 39.033933 \r\nL 239.007257 36.52478 \r\nL 242.081637 36.298841 \r\nL 245.156018 37.785299 \r\nL 248.230398 33.563749 \r\nL 251.304778 38.415565 \r\nL 254.379158 36.52478 \r\nL 257.453538 38.415565 \r\nL 260.527918 28.777331 \r\nL 263.602299 34.931295 \r\nL 266.676679 35.264262 \r\nL 269.751059 35.615062 \r\nL 272.825439 36.640725 \r\nL 275.899819 30.852439 \r\nL 278.974199 33.373477 \r\nL 282.04858 30.144877 \r\nL 285.12296 31.167572 \r\nL 288.19734 33.68861 \r\nL 291.27172 30.852439 \r\nL 294.3461 28.961654 \r\nL 297.42048 29.59192 \r\nL 300.494861 27.386003 \r\nL 303.569241 28.961654 \r\nL 306.643621 27.07087 \r\nL 309.718001 26.125484 \r\nL 312.792381 27.701136 \r\nL 315.866761 23.2893 \r\nL 318.941142 22.281484 \r\nL 322.015522 26.440604 \r\nL 325.089902 27.067902 \r\nL 328.164282 23.990913 \r\nL 331.238662 32.112958 \r\nL 334.313042 32.538086 \r\nL 337.387423 22.623367 \r\nL 340.461803 28.961654 \r\nL 343.536183 22.97418 \r\nL 346.610563 28.016269 \r\nL 349.684943 23.604433 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#p831cd925e8)\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_16\">\r\n    <path clip-path=\"url(#p831cd925e8)\" d=\"M 45.321307 181.809875 \r\nL 48.395687 174.938181 \r\nL 51.470067 174.938181 \r\nL 54.544447 176.410687 \r\nL 57.618827 163.158135 \r\nL 60.693208 165.61231 \r\nL 63.767588 170.520666 \r\nL 66.841968 158.249785 \r\nL 69.916348 160.213123 \r\nL 72.990728 156.286442 \r\nL 76.065108 152.359761 \r\nL 79.139489 160.70396 \r\nL 82.213869 163.648973 \r\nL 85.288249 152.850598 \r\nL 88.362629 155.795604 \r\nL 91.437009 161.685629 \r\nL 94.511389 159.722292 \r\nL 97.58577 153.832267 \r\nL 100.66015 155.304773 \r\nL 103.73453 153.832267 \r\nL 106.80891 156.286442 \r\nL 109.88329 154.323104 \r\nL 112.95767 153.341429 \r\nL 116.032051 154.323104 \r\nL 119.106431 155.795604 \r\nL 122.180811 154.813935 \r\nL 125.255191 161.194791 \r\nL 128.329571 157.758948 \r\nL 131.403951 154.813935 \r\nL 134.478332 161.685629 \r\nL 137.552712 155.304773 \r\nL 140.627092 154.813935 \r\nL 143.701472 155.304773 \r\nL 146.775852 155.304773 \r\nL 149.850232 157.758948 \r\nL 152.924613 162.176466 \r\nL 155.998993 150.887254 \r\nL 159.073373 158.740616 \r\nL 162.147753 153.341429 \r\nL 165.222133 157.758948 \r\nL 168.296513 154.323104 \r\nL 171.370894 143.524724 \r\nL 174.445274 149.905586 \r\nL 177.519654 151.868923 \r\nL 180.594034 145.488067 \r\nL 183.668414 160.213123 \r\nL 186.742794 149.905586 \r\nL 189.817175 153.832267 \r\nL 192.891555 155.304773 \r\nL 195.965935 149.905586 \r\nL 199.040315 150.887254 \r\nL 202.114695 153.341429 \r\nL 205.189075 146.960573 \r\nL 208.263456 145.978905 \r\nL 211.337836 147.451411 \r\nL 214.412216 153.341429 \r\nL 217.486596 146.960573 \r\nL 220.560976 143.524724 \r\nL 223.635356 144.99723 \r\nL 226.709737 147.451411 \r\nL 229.784117 148.923917 \r\nL 232.858497 149.905586 \r\nL 235.932877 147.942242 \r\nL 239.007257 149.905586 \r\nL 242.081637 144.99723 \r\nL 245.156018 145.978905 \r\nL 248.230398 145.488067 \r\nL 251.304778 144.506399 \r\nL 254.379158 145.978905 \r\nL 257.453538 145.488067 \r\nL 260.527918 152.850598 \r\nL 263.602299 141.561386 \r\nL 266.676679 148.43308 \r\nL 269.751059 151.378092 \r\nL 272.825439 152.850598 \r\nL 275.899819 149.905586 \r\nL 278.974199 159.231454 \r\nL 282.04858 156.286442 \r\nL 285.12296 148.923917 \r\nL 288.19734 154.813935 \r\nL 291.27172 150.887254 \r\nL 294.3461 151.868923 \r\nL 297.42048 148.43308 \r\nL 300.494861 147.451411 \r\nL 303.569241 149.905586 \r\nL 306.643621 146.960573 \r\nL 309.718001 147.942242 \r\nL 312.792381 155.304773 \r\nL 315.866761 153.341429 \r\nL 318.941142 148.43308 \r\nL 322.015522 152.359761 \r\nL 325.089902 156.286442 \r\nL 328.164282 154.813935 \r\nL 331.238662 144.99723 \r\nL 334.313042 150.887254 \r\nL 337.387423 149.905586 \r\nL 340.461803 151.378092 \r\nL 343.536183 155.304773 \r\nL 346.610563 143.033892 \r\nL 349.684943 149.905586 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 30.103125 228.439219 \r\nL 30.103125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 364.903125 228.439219 \r\nL 364.903125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 30.103125 228.439219 \r\nL 364.903125 228.439219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 30.103125 10.999219 \r\nL 364.903125 10.999219 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"legend_1\">\r\n    <g id=\"patch_7\">\r\n     <path d=\"M 118.800781 223.439219 \r\nL 276.205469 223.439219 \r\nQ 278.205469 223.439219 278.205469 221.439219 \r\nL 278.205469 162.892344 \r\nQ 278.205469 160.892344 276.205469 160.892344 \r\nL 118.800781 160.892344 \r\nQ 116.800781 160.892344 116.800781 162.892344 \r\nL 116.800781 221.439219 \r\nQ 116.800781 223.439219 118.800781 223.439219 \r\nz\r\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\r\n    </g>\r\n    <g id=\"line2d_17\">\r\n     <path d=\"M 120.800781 168.990781 \r\nL 140.800781 168.990781 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_18\"/>\r\n    <g id=\"text_13\">\r\n     <!-- loss -->\r\n     <g transform=\"translate(148.800781 172.490781)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\n\" id=\"DejaVuSans-108\"/>\r\n       <path d=\"M 30.609375 48.390625 \r\nQ 23.390625 48.390625 19.1875 42.75 \r\nQ 14.984375 37.109375 14.984375 27.296875 \r\nQ 14.984375 17.484375 19.15625 11.84375 \r\nQ 23.34375 6.203125 30.609375 6.203125 \r\nQ 37.796875 6.203125 41.984375 11.859375 \r\nQ 46.1875 17.53125 46.1875 27.296875 \r\nQ 46.1875 37.015625 41.984375 42.703125 \r\nQ 37.796875 48.390625 30.609375 48.390625 \r\nz\r\nM 30.609375 56 \r\nQ 42.328125 56 49.015625 48.375 \r\nQ 55.71875 40.765625 55.71875 27.296875 \r\nQ 55.71875 13.875 49.015625 6.21875 \r\nQ 42.328125 -1.421875 30.609375 -1.421875 \r\nQ 18.84375 -1.421875 12.171875 6.21875 \r\nQ 5.515625 13.875 5.515625 27.296875 \r\nQ 5.515625 40.765625 12.171875 48.375 \r\nQ 18.84375 56 30.609375 56 \r\nz\r\n\" id=\"DejaVuSans-111\"/>\r\n       <path d=\"M 44.28125 53.078125 \r\nL 44.28125 44.578125 \r\nQ 40.484375 46.53125 36.375 47.5 \r\nQ 32.28125 48.484375 27.875 48.484375 \r\nQ 21.1875 48.484375 17.84375 46.4375 \r\nQ 14.5 44.390625 14.5 40.28125 \r\nQ 14.5 37.15625 16.890625 35.375 \r\nQ 19.28125 33.59375 26.515625 31.984375 \r\nL 29.59375 31.296875 \r\nQ 39.15625 29.25 43.1875 25.515625 \r\nQ 47.21875 21.78125 47.21875 15.09375 \r\nQ 47.21875 7.46875 41.1875 3.015625 \r\nQ 35.15625 -1.421875 24.609375 -1.421875 \r\nQ 20.21875 -1.421875 15.453125 -0.5625 \r\nQ 10.6875 0.296875 5.421875 2 \r\nL 5.421875 11.28125 \r\nQ 10.40625 8.6875 15.234375 7.390625 \r\nQ 20.0625 6.109375 24.8125 6.109375 \r\nQ 31.15625 6.109375 34.5625 8.28125 \r\nQ 37.984375 10.453125 37.984375 14.40625 \r\nQ 37.984375 18.0625 35.515625 20.015625 \r\nQ 33.0625 21.96875 24.703125 23.78125 \r\nL 21.578125 24.515625 \r\nQ 13.234375 26.265625 9.515625 29.90625 \r\nQ 5.8125 33.546875 5.8125 39.890625 \r\nQ 5.8125 47.609375 11.28125 51.796875 \r\nQ 16.75 56 26.8125 56 \r\nQ 31.78125 56 36.171875 55.265625 \r\nQ 40.578125 54.546875 44.28125 53.078125 \r\nz\r\n\" id=\"DejaVuSans-115\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"27.783203\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"88.964844\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"141.064453\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_19\">\r\n     <path d=\"M 120.800781 183.668906 \r\nL 140.800781 183.668906 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_20\"/>\r\n    <g id=\"text_14\">\r\n     <!-- categorical_accuracy -->\r\n     <g transform=\"translate(148.800781 187.168906)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 48.78125 52.59375 \r\nL 48.78125 44.1875 \r\nQ 44.96875 46.296875 41.140625 47.34375 \r\nQ 37.3125 48.390625 33.40625 48.390625 \r\nQ 24.65625 48.390625 19.8125 42.84375 \r\nQ 14.984375 37.3125 14.984375 27.296875 \r\nQ 14.984375 17.28125 19.8125 11.734375 \r\nQ 24.65625 6.203125 33.40625 6.203125 \r\nQ 37.3125 6.203125 41.140625 7.25 \r\nQ 44.96875 8.296875 48.78125 10.40625 \r\nL 48.78125 2.09375 \r\nQ 45.015625 0.34375 40.984375 -0.53125 \r\nQ 36.96875 -1.421875 32.421875 -1.421875 \r\nQ 20.0625 -1.421875 12.78125 6.34375 \r\nQ 5.515625 14.109375 5.515625 27.296875 \r\nQ 5.515625 40.671875 12.859375 48.328125 \r\nQ 20.21875 56 33.015625 56 \r\nQ 37.15625 56 41.109375 55.140625 \r\nQ 45.0625 54.296875 48.78125 52.59375 \r\nz\r\n\" id=\"DejaVuSans-99\"/>\r\n       <path d=\"M 34.28125 27.484375 \r\nQ 23.390625 27.484375 19.1875 25 \r\nQ 14.984375 22.515625 14.984375 16.5 \r\nQ 14.984375 11.71875 18.140625 8.90625 \r\nQ 21.296875 6.109375 26.703125 6.109375 \r\nQ 34.1875 6.109375 38.703125 11.40625 \r\nQ 43.21875 16.703125 43.21875 25.484375 \r\nL 43.21875 27.484375 \r\nz\r\nM 52.203125 31.203125 \r\nL 52.203125 0 \r\nL 43.21875 0 \r\nL 43.21875 8.296875 \r\nQ 40.140625 3.328125 35.546875 0.953125 \r\nQ 30.953125 -1.421875 24.3125 -1.421875 \r\nQ 15.921875 -1.421875 10.953125 3.296875 \r\nQ 6 8.015625 6 15.921875 \r\nQ 6 25.140625 12.171875 29.828125 \r\nQ 18.359375 34.515625 30.609375 34.515625 \r\nL 43.21875 34.515625 \r\nL 43.21875 35.40625 \r\nQ 43.21875 41.609375 39.140625 45 \r\nQ 35.0625 48.390625 27.6875 48.390625 \r\nQ 23 48.390625 18.546875 47.265625 \r\nQ 14.109375 46.140625 10.015625 43.890625 \r\nL 10.015625 52.203125 \r\nQ 14.9375 54.109375 19.578125 55.046875 \r\nQ 24.21875 56 28.609375 56 \r\nQ 40.484375 56 46.34375 49.84375 \r\nQ 52.203125 43.703125 52.203125 31.203125 \r\nz\r\n\" id=\"DejaVuSans-97\"/>\r\n       <path d=\"M 18.3125 70.21875 \r\nL 18.3125 54.6875 \r\nL 36.8125 54.6875 \r\nL 36.8125 47.703125 \r\nL 18.3125 47.703125 \r\nL 18.3125 18.015625 \r\nQ 18.3125 11.328125 20.140625 9.421875 \r\nQ 21.96875 7.515625 27.59375 7.515625 \r\nL 36.8125 7.515625 \r\nL 36.8125 0 \r\nL 27.59375 0 \r\nQ 17.1875 0 13.234375 3.875 \r\nQ 9.28125 7.765625 9.28125 18.015625 \r\nL 9.28125 47.703125 \r\nL 2.6875 47.703125 \r\nL 2.6875 54.6875 \r\nL 9.28125 54.6875 \r\nL 9.28125 70.21875 \r\nz\r\n\" id=\"DejaVuSans-116\"/>\r\n       <path d=\"M 56.203125 29.59375 \r\nL 56.203125 25.203125 \r\nL 14.890625 25.203125 \r\nQ 15.484375 15.921875 20.484375 11.0625 \r\nQ 25.484375 6.203125 34.421875 6.203125 \r\nQ 39.59375 6.203125 44.453125 7.46875 \r\nQ 49.3125 8.734375 54.109375 11.28125 \r\nL 54.109375 2.78125 \r\nQ 49.265625 0.734375 44.1875 -0.34375 \r\nQ 39.109375 -1.421875 33.890625 -1.421875 \r\nQ 20.796875 -1.421875 13.15625 6.1875 \r\nQ 5.515625 13.8125 5.515625 26.8125 \r\nQ 5.515625 40.234375 12.765625 48.109375 \r\nQ 20.015625 56 32.328125 56 \r\nQ 43.359375 56 49.78125 48.890625 \r\nQ 56.203125 41.796875 56.203125 29.59375 \r\nz\r\nM 47.21875 32.234375 \r\nQ 47.125 39.59375 43.09375 43.984375 \r\nQ 39.0625 48.390625 32.421875 48.390625 \r\nQ 24.90625 48.390625 20.390625 44.140625 \r\nQ 15.875 39.890625 15.1875 32.171875 \r\nz\r\n\" id=\"DejaVuSans-101\"/>\r\n       <path d=\"M 45.40625 27.984375 \r\nQ 45.40625 37.75 41.375 43.109375 \r\nQ 37.359375 48.484375 30.078125 48.484375 \r\nQ 22.859375 48.484375 18.828125 43.109375 \r\nQ 14.796875 37.75 14.796875 27.984375 \r\nQ 14.796875 18.265625 18.828125 12.890625 \r\nQ 22.859375 7.515625 30.078125 7.515625 \r\nQ 37.359375 7.515625 41.375 12.890625 \r\nQ 45.40625 18.265625 45.40625 27.984375 \r\nz\r\nM 54.390625 6.78125 \r\nQ 54.390625 -7.171875 48.1875 -13.984375 \r\nQ 42 -20.796875 29.203125 -20.796875 \r\nQ 24.46875 -20.796875 20.265625 -20.09375 \r\nQ 16.0625 -19.390625 12.109375 -17.921875 \r\nL 12.109375 -9.1875 \r\nQ 16.0625 -11.328125 19.921875 -12.34375 \r\nQ 23.78125 -13.375 27.78125 -13.375 \r\nQ 36.625 -13.375 41.015625 -8.765625 \r\nQ 45.40625 -4.15625 45.40625 5.171875 \r\nL 45.40625 9.625 \r\nQ 42.625 4.78125 38.28125 2.390625 \r\nQ 33.9375 0 27.875 0 \r\nQ 17.828125 0 11.671875 7.65625 \r\nQ 5.515625 15.328125 5.515625 27.984375 \r\nQ 5.515625 40.671875 11.671875 48.328125 \r\nQ 17.828125 56 27.875 56 \r\nQ 33.9375 56 38.28125 53.609375 \r\nQ 42.625 51.21875 45.40625 46.390625 \r\nL 45.40625 54.6875 \r\nL 54.390625 54.6875 \r\nz\r\n\" id=\"DejaVuSans-103\"/>\r\n       <path d=\"M 41.109375 46.296875 \r\nQ 39.59375 47.171875 37.8125 47.578125 \r\nQ 36.03125 48 33.890625 48 \r\nQ 26.265625 48 22.1875 43.046875 \r\nQ 18.109375 38.09375 18.109375 28.8125 \r\nL 18.109375 0 \r\nL 9.078125 0 \r\nL 9.078125 54.6875 \r\nL 18.109375 54.6875 \r\nL 18.109375 46.1875 \r\nQ 20.953125 51.171875 25.484375 53.578125 \r\nQ 30.03125 56 36.53125 56 \r\nQ 37.453125 56 38.578125 55.875 \r\nQ 39.703125 55.765625 41.0625 55.515625 \r\nz\r\n\" id=\"DejaVuSans-114\"/>\r\n       <path d=\"M 9.421875 54.6875 \r\nL 18.40625 54.6875 \r\nL 18.40625 0 \r\nL 9.421875 0 \r\nz\r\nM 9.421875 75.984375 \r\nL 18.40625 75.984375 \r\nL 18.40625 64.59375 \r\nL 9.421875 64.59375 \r\nz\r\n\" id=\"DejaVuSans-105\"/>\r\n       <path d=\"M 50.984375 -16.609375 \r\nL 50.984375 -23.578125 \r\nL -0.984375 -23.578125 \r\nL -0.984375 -16.609375 \r\nz\r\n\" id=\"DejaVuSans-95\"/>\r\n       <path d=\"M 8.5 21.578125 \r\nL 8.5 54.6875 \r\nL 17.484375 54.6875 \r\nL 17.484375 21.921875 \r\nQ 17.484375 14.15625 20.5 10.265625 \r\nQ 23.53125 6.390625 29.59375 6.390625 \r\nQ 36.859375 6.390625 41.078125 11.03125 \r\nQ 45.3125 15.671875 45.3125 23.6875 \r\nL 45.3125 54.6875 \r\nL 54.296875 54.6875 \r\nL 54.296875 0 \r\nL 45.3125 0 \r\nL 45.3125 8.40625 \r\nQ 42.046875 3.421875 37.71875 1 \r\nQ 33.40625 -1.421875 27.6875 -1.421875 \r\nQ 18.265625 -1.421875 13.375 4.4375 \r\nQ 8.5 10.296875 8.5 21.578125 \r\nz\r\nM 31.109375 56 \r\nz\r\n\" id=\"DejaVuSans-117\"/>\r\n       <path d=\"M 32.171875 -5.078125 \r\nQ 28.375 -14.84375 24.75 -17.8125 \r\nQ 21.140625 -20.796875 15.09375 -20.796875 \r\nL 7.90625 -20.796875 \r\nL 7.90625 -13.28125 \r\nL 13.1875 -13.28125 \r\nQ 16.890625 -13.28125 18.9375 -11.515625 \r\nQ 21 -9.765625 23.484375 -3.21875 \r\nL 25.09375 0.875 \r\nL 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 11.921875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nz\r\n\" id=\"DejaVuSans-121\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"54.980469\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"116.259766\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"155.46875\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"216.992188\" xlink:href=\"#DejaVuSans-103\"/>\r\n      <use x=\"280.46875\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"341.650391\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"382.763672\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"410.546875\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"465.527344\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"526.806641\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"554.589844\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"604.589844\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"665.869141\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"720.849609\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"775.830078\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"839.208984\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"880.322266\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"941.601562\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"996.582031\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_21\">\r\n     <path d=\"M 120.800781 198.625156 \r\nL 140.800781 198.625156 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_22\"/>\r\n    <g id=\"text_15\">\r\n     <!-- val_loss -->\r\n     <g transform=\"translate(148.800781 202.125156)scale(0.1 -0.1)\">\r\n      <defs>\r\n       <path d=\"M 2.984375 54.6875 \r\nL 12.5 54.6875 \r\nL 29.59375 8.796875 \r\nL 46.6875 54.6875 \r\nL 56.203125 54.6875 \r\nL 35.6875 0 \r\nL 23.484375 0 \r\nz\r\n\" id=\"DejaVuSans-118\"/>\r\n      </defs>\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"226.025391\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"287.207031\" xlink:href=\"#DejaVuSans-115\"/>\r\n      <use x=\"339.306641\" xlink:href=\"#DejaVuSans-115\"/>\r\n     </g>\r\n    </g>\r\n    <g id=\"line2d_23\">\r\n     <path d=\"M 120.800781 213.581406 \r\nL 140.800781 213.581406 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n    </g>\r\n    <g id=\"line2d_24\"/>\r\n    <g id=\"text_16\">\r\n     <!-- val_categorical_accuracy -->\r\n     <g transform=\"translate(148.800781 217.081406)scale(0.1 -0.1)\">\r\n      <use xlink:href=\"#DejaVuSans-118\"/>\r\n      <use x=\"59.179688\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"120.458984\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"148.242188\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"198.242188\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"253.222656\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"314.501953\" xlink:href=\"#DejaVuSans-116\"/>\r\n      <use x=\"353.710938\" xlink:href=\"#DejaVuSans-101\"/>\r\n      <use x=\"415.234375\" xlink:href=\"#DejaVuSans-103\"/>\r\n      <use x=\"478.710938\" xlink:href=\"#DejaVuSans-111\"/>\r\n      <use x=\"539.892578\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"581.005859\" xlink:href=\"#DejaVuSans-105\"/>\r\n      <use x=\"608.789062\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"663.769531\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"725.048828\" xlink:href=\"#DejaVuSans-108\"/>\r\n      <use x=\"752.832031\" xlink:href=\"#DejaVuSans-95\"/>\r\n      <use x=\"802.832031\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"864.111328\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"919.091797\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"974.072266\" xlink:href=\"#DejaVuSans-117\"/>\r\n      <use x=\"1037.451172\" xlink:href=\"#DejaVuSans-114\"/>\r\n      <use x=\"1078.564453\" xlink:href=\"#DejaVuSans-97\"/>\r\n      <use x=\"1139.84375\" xlink:href=\"#DejaVuSans-99\"/>\r\n      <use x=\"1194.824219\" xlink:href=\"#DejaVuSans-121\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p831cd925e8\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"10.999219\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Performance of the model on training and validation sets\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1*X GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=(1024*4))])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}