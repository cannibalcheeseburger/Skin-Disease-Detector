{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('doc-ai': conda)",
   "metadata": {
    "interpreter": {
     "hash": "167e8cde34a5a8dfb69dbca24028cf1777662ffa32bb3f73567ca125b7f97bb5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Xception model\n",
    "base_model = tf.keras.applications.Xception(\n",
    "    include_top=False,\n",
    "    weights=\"xception_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n",
    "    input_shape=(256, 256, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the model\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making layers of base model untrainable so that their weights won't change during training for first few epochs\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the input and output layers of the base model\n",
    "base_input = base_model.layers[0].input\n",
    "base_output = base_model.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layers to the base model\n",
    "l1 = Flatten()(base_output)\n",
    "l2 = Dense(512, activation='elu')(l1)\n",
    "l3 = Dropout(0.2)(l2)\n",
    "l4 = Dense(256, activation='elu')(l3)\n",
    "l5 = Dropout(0.2)(l4)\n",
    "l6 = Dense(12, activation='softmax')(l5)\n",
    "\n",
    "model = tf.keras.Model(inputs=base_input, outputs=l6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the data and augmenting it:\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.15,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'C://Users//mukul//Documents//#Programing//Skin_Pigment_Analysis//Dataset//OG_Train',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=69,\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "        'C://Users//mukul//Documents//#Programing//Skin_Pigment_Analysis//Dataset//OG_Valid',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=17,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model i.e selecting the optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model for few epoch so that the weights of pretrained layers don't change abruptly\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=25,\n",
    "      validation_data=(valid_generator),  \n",
    "      epochs=5,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making some layers of base model trainable \n",
    "for layer in base_model.layers[-6:-1]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the callbacks\n",
    "\n",
    "# checkpoint_cb will save the model which will perform the best on validation set\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('C://Users//mukul//Documents//#Programing//Skin_Pigment_Analysis//best_model.h5', save_best_only=True)\n",
    "\n",
    "# early_stoping_cb will stop the model traning once it stops improving\n",
    "early_stoping_cb = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model i.e selecting the optimizer and loss function\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "history = model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=,\n",
    "      validation_data=(valid_generator),\n",
    "      callbacks=[checkpoint_cb, early_stoping_cb],  \n",
    "      epochs=100,\n",
    "      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of the model on training and validation sets\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}