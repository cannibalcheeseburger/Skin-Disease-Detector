{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "9bb8cabea485496b2bfe23854d3c1f468dc9354f49d3cf36deb2f53ba2eb8792"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Augmentatiom to increase out Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python.keras.preprocessing'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0dcca6fa4988>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python.keras.preprocessing'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset/Skin_Diseases\\Acne_Cystic\n",
      "Dataset/Skin_Diseases\\Allergic_Contact_Dermatitis\n",
      "Dataset/Skin_Diseases\\Eczema\n",
      "Dataset/Skin_Diseases\\Impetigo\n",
      "Dataset/Skin_Diseases\\Intertrigo\n",
      "Dataset/Skin_Diseases\\Lichen_Planus\n",
      "Dataset/Skin_Diseases\\Psoriasis_Chronic_Plaque\n",
      "Dataset/Skin_Diseases\\Psoriasis_Hands_Legs\n",
      "Dataset/Skin_Diseases\\Rosacea\n",
      "Dataset/Skin_Diseases\\Schamberg_Disease\n",
      "Dataset/Skin_Diseases\\Tinea_Ringworm_Body\n",
      "Dataset/Skin_Diseases\\Tinea_Ringworm_Groin\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentatiom to increase out Dataset\n",
    "from glob import glob\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "\n",
    "path = 'Dataset/Skin_Diseases'\n",
    "for folder in glob(path+'/*'):\n",
    "    print(folder)\n",
    "    \n",
    "    for idx, im in list(enumerate(glob(folder+'/*'))):\n",
    "        img = load_img(im)   # this is a PIL image\n",
    "        x = img_to_array(img)  # this is a Numpy array with shape (3, 150, 150)\n",
    "        x = x.reshape((1,) + x.shape)  # this is a Numpy array with shape (1, 3, 150, 150)\n",
    "\n",
    "        # the .flow() command below generates batches of randomly transformed images\n",
    "        # and saves the results to the `preview/` directory\n",
    "        i = 0\n",
    "        for batch in datagen.flow(x, batch_size=1,\n",
    "                                save_to_dir= folder, save_prefix='copy', save_format='jpeg'):\n",
    "            i += 1\n",
    "            if i > 10:\n",
    "                break  # otherwise the generator would loop indefinitely\n"
   ]
  },
  {
   "source": [
    "# Dividing Dataset into Training & Validation sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset/Skin_Diseases\\Acne_Cystic\n",
      "no of images in this folder: 1636\n",
      "Dataset/Valid/Acne_Cystic/\n",
      "Dataset/Train/Acne_Cystic/\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset/Skin_Diseases\\Allergic_Contact_Dermatitis\n",
      "no of images in this folder: 1921\n",
      "Dataset/Valid/Allergic_Contact_Dermatitis/\n",
      "Dataset/Train/Allergic_Contact_Dermatitis/\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset/Skin_Diseases\\Eczema\n",
      "no of images in this folder: 2919\n",
      "Dataset/Valid/Eczema/\n",
      "Dataset/Train/Eczema/\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset/Skin_Diseases\\Impetigo\n",
      "no of images in this folder: 873\n",
      "Dataset/Valid/Impetigo/\n",
      "Dataset/Train/Impetigo/\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset/Skin_Diseases\\Intertrigo\n",
      "no of images in this folder: 1067\n",
      "Dataset/Valid/Intertrigo/\n",
      "Dataset/Train/Intertrigo/\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset/Skin_Diseases\\Lichen_Planus\n",
      "no of images in this folder: 2809\n",
      "Dataset/Valid/Lichen_Planus/\n",
      "Dataset/Train/Lichen_Planus/\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset/Skin_Diseases\\Psoriasis_Chronic_Plaque\n",
      "no of images in this folder: 3355\n",
      "Dataset/Valid/Psoriasis_Chronic_Plaque/\n",
      "Dataset/Train/Psoriasis_Chronic_Plaque/\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset/Skin_Diseases\\Psoriasis_Hands_Legs\n",
      "no of images in this folder: 1996\n",
      "Dataset/Valid/Psoriasis_Hands_Legs/\n",
      "Dataset/Train/Psoriasis_Hands_Legs/\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset/Skin_Diseases\\Rosacea\n",
      "no of images in this folder: 2332\n",
      "Dataset/Valid/Rosacea/\n",
      "Dataset/Train/Rosacea/\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset/Skin_Diseases\\Schamberg_Disease\n",
      "no of images in this folder: 899\n",
      "Dataset/Valid/Schamberg_Disease/\n",
      "Dataset/Train/Schamberg_Disease/\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset/Skin_Diseases\\Tinea_Ringworm_Body\n",
      "no of images in this folder: 2393\n",
      "Dataset/Valid/Tinea_Ringworm_Body/\n",
      "Dataset/Train/Tinea_Ringworm_Body/\n",
      "---------------------------------------------\n",
      "\n",
      "Dataset/Skin_Diseases\\Tinea_Ringworm_Groin\n",
      "no of images in this folder: 1418\n",
      "Dataset/Valid/Tinea_Ringworm_Groin/\n",
      "Dataset/Train/Tinea_Ringworm_Groin/\n",
      "---------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train-Valid Partitioning\n",
    "from shutil import copy2\n",
    "import random\n",
    "random.seed(17)\n",
    "\n",
    "# This is the path where our dataset is stored\n",
    "path = 'Dataset/Skin_Diseases'\n",
    "# These are the paths where we intend to store our train & valid sets\n",
    "valid = 'Dataset/Valid'\n",
    "train = 'Dataset/Train'\n",
    "\n",
    "if not os.path.exists(valid):\n",
    "\tos.makedirs(valid)\n",
    "if not os.path.exists(train):\n",
    "\tos.makedirs(train)\n",
    "# glob module is used to retrieve files/pathnames matching a specified pattern \n",
    "for folder in glob(path+'/*'):\n",
    "\tprint(folder)\n",
    "\n",
    "\t# find number of images in folder\n",
    "\tno_images_in_folder = len(os.listdir(folder))\n",
    "\tprint(\"no of images in this folder: {}\".format(no_images_in_folder))\n",
    "\n",
    "\t# make new folder inside test and train\n",
    "\tfolder_valid = valid+'/'+folder.split('\\\\')[1]+'/'\n",
    "\tfolder_train = train+'/'+folder.split('\\\\')[1]+'/'\n",
    "\tprint(folder_valid)\n",
    "\tprint(folder_train)\n",
    "\n",
    "\tif not os.path.exists(folder_valid):\n",
    "\t\tos.makedirs(folder_valid)\n",
    "\tif not os.path.exists(folder_train):\n",
    "\t\tos.makedirs(folder_train)\n",
    "\n",
    "\tprint('---------------------------------------------\\n')\n",
    "\n",
    "\t#Divide the images in Datase to Train set & valdi set by 0.8 : 0.2 ratio\n",
    "\tvalid_num = int(no_images_in_folder*0.25)\n",
    "\t\t\n",
    "\t# Shuffle the data in the folder to divide evenly\n",
    "\tx = list(enumerate(glob(folder+'/*')))\n",
    "\trandom.shuffle(x)\n",
    "\n",
    "    # iterate from 0 to valid_num and copy to valid_folder\n",
    "\t# iterate valid_num to end and copy to train_folder\n",
    "\tcount = 0\n",
    "\tfor idx, im in x:\n",
    "\t\tif count <= valid_num:\n",
    "\t\t# copy to valid\n",
    "\t\t\tcopy2(im, folder_valid)\n",
    "\t\t\tcount += 1\n",
    "\t\telse:\n",
    "\t\t# copy to train\n",
    "\t\t\tcopy2(im, folder_train)\n",
    "\t\t\tcount += 1"
   ]
  },
  {
   "source": [
    "# Storing the Dataset in h5py & pickle files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATADIR_VALID = 'Dataset\\Valid'\n",
    "DATADIR_TRAIN = 'Dataset\\Train'\n",
    "CATEGORIES = ['Acne_Cystic', 'Allergic_Contact_Dermatitis', 'Eczema', 'Impetigo', 'Intertrigo', 'Lichen_Planus', 'Psoriasis_Chronic_Plaque', 'Psoriasis_Hands_Legs', 'Rosacea', 'Schamberg_Disease', 'Tinea_Ringworm_Body', 'Tinea_Ringworm_Groin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  2%|▏         | 29/1226 [00:00<00:04, 284.22it/s]\n",
      " TRAINING DATA\n",
      "\n",
      "Acne_Cystic\n",
      "100%|██████████| 1226/1226 [00:03<00:00, 372.99it/s]\n",
      "  2%|▏         | 35/1439 [00:00<00:04, 340.83it/s]\n",
      "Allergic_Contact_Dermatitis\n",
      "100%|██████████| 1439/1439 [00:03<00:00, 365.05it/s]\n",
      "  2%|▏         | 46/2168 [00:00<00:04, 454.12it/s]\n",
      "Eczema\n",
      "100%|██████████| 2168/2168 [00:05<00:00, 390.87it/s]\n",
      "  6%|▌         | 39/659 [00:00<00:01, 383.21it/s]\n",
      "Impetigo\n",
      "100%|██████████| 659/659 [00:01<00:00, 364.21it/s]\n",
      "  4%|▍         | 31/813 [00:00<00:02, 282.85it/s]\n",
      "Intertrigo\n",
      "100%|██████████| 813/813 [00:02<00:00, 338.21it/s]\n",
      "  4%|▍         | 88/2123 [00:00<00:04, 430.80it/s]\n",
      "Lichen_Planus\n",
      "100%|██████████| 2123/2123 [00:06<00:00, 350.68it/s]\n",
      "  0%|          | 0/2525 [00:00<?, ?it/s]\n",
      "Psoriasis_Chronic_Plaque\n",
      "100%|██████████| 2525/2525 [00:09<00:00, 262.21it/s]\n",
      "  3%|▎         | 38/1508 [00:00<00:03, 374.90it/s]\n",
      "Psoriasis_Hands_Legs\n",
      "100%|██████████| 1508/1508 [00:04<00:00, 362.37it/s]\n",
      "  2%|▏         | 29/1727 [00:00<00:05, 288.06it/s]\n",
      "Rosacea\n",
      "100%|██████████| 1727/1727 [00:04<00:00, 362.47it/s]\n",
      "  6%|▌         | 41/673 [00:00<00:01, 403.57it/s]\n",
      "Schamberg_Disease\n",
      "100%|██████████| 673/673 [00:01<00:00, 347.42it/s]\n",
      "  2%|▏         | 32/1792 [00:00<00:05, 314.57it/s]\n",
      "Tinea_Ringworm_Body\n",
      "100%|██████████| 1792/1792 [00:05<00:00, 316.26it/s]\n",
      "  3%|▎         | 34/1060 [00:00<00:03, 333.00it/s]\n",
      "Tinea_Ringworm_Groin\n",
      "100%|██████████| 1060/1060 [00:03<00:00, 318.53it/s]\n",
      "  7%|▋         | 29/410 [00:00<00:01, 280.93it/s]\n",
      " VALIDATION DATA\n",
      "\n",
      "Acne_Cystic\n",
      "100%|██████████| 410/410 [00:01<00:00, 334.25it/s]\n",
      "  7%|▋         | 36/481 [00:00<00:01, 359.01it/s]\n",
      "Allergic_Contact_Dermatitis\n",
      "100%|██████████| 481/481 [00:01<00:00, 352.16it/s]\n",
      "  5%|▍         | 36/724 [00:00<00:01, 353.03it/s]\n",
      "Eczema\n",
      "100%|██████████| 724/724 [00:03<00:00, 183.35it/s]\n",
      " 16%|█▌        | 35/220 [00:00<00:00, 342.35it/s]\n",
      "Impetigo\n",
      "100%|██████████| 220/220 [00:00<00:00, 378.60it/s]\n",
      " 15%|█▌        | 42/272 [00:00<00:00, 371.89it/s]\n",
      "Intertrigo\n",
      "100%|██████████| 272/272 [00:00<00:00, 413.73it/s]\n",
      "\n",
      "Lichen_Planus\n",
      "100%|██████████| 708/708 [00:01<00:00, 362.54it/s]\n",
      "  4%|▍         | 36/843 [00:00<00:02, 359.83it/s]\n",
      "Psoriasis_Chronic_Plaque\n",
      "100%|██████████| 843/843 [00:02<00:00, 345.92it/s]\n",
      "  7%|▋         | 33/504 [00:00<00:01, 325.38it/s]\n",
      "Psoriasis_Hands_Legs\n",
      "100%|██████████| 504/504 [00:01<00:00, 420.15it/s]\n",
      "  6%|▌         | 35/577 [00:00<00:01, 342.79it/s]\n",
      "Rosacea\n",
      "100%|██████████| 577/577 [00:01<00:00, 467.17it/s]\n",
      " 21%|██▏       | 48/225 [00:00<00:00, 471.10it/s]\n",
      "Schamberg_Disease\n",
      "100%|██████████| 225/225 [00:00<00:00, 444.11it/s]\n",
      "  8%|▊         | 49/598 [00:00<00:01, 486.80it/s]\n",
      "Tinea_Ringworm_Body\n",
      "100%|██████████| 598/598 [00:01<00:00, 439.39it/s]\n",
      " 12%|█▏        | 44/354 [00:00<00:00, 439.41it/s]\n",
      "Tinea_Ringworm_Groin\n",
      "100%|██████████| 354/354 [00:00<00:00, 430.29it/s]\n",
      "\n",
      "Training Samples: 17706\n",
      "Validation Samples: 5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "training_data = []\n",
    "validation_data = []\n",
    "\n",
    "\n",
    "def create_training_data():\n",
    "    print('\\n TRAINING DATA')\n",
    "    for category in CATEGORIES:  \n",
    "\n",
    "        print('\\n' + category)\n",
    "        path = os.path.join(DATADIR_TRAIN,category)  # create path to different catagories\n",
    "        class_name = CATEGORIES.index(category)  # get the classification  in numbers (0, 1,2, 3,...)\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image of every catagory\n",
    "            img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "            training_data.append([new_array, class_name])  # add this to our training_data\n",
    "            \n",
    "\n",
    "\n",
    "def create_validation_data():\n",
    "    print('\\n VALIDATION DATA')\n",
    "    for category in CATEGORIES:  \n",
    "\n",
    "        print('\\n' + category)\n",
    "        path = os.path.join(DATADIR_VALID,category)  # create path to different catagories\n",
    "        class_name = CATEGORIES.index(category)  # get the classification  in numbers (0, 1,2, 3,...)  \n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image of every catagory\n",
    "            img_array = cv2.imread(os.path.join(path,img))  # convert to array\n",
    "            new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "            validation_data.append([new_array, class_name])  # add this to our training_data\n",
    "            \n",
    "\n",
    "create_training_data()\n",
    "create_validation_data()\n",
    "\n",
    "print('\\n')\n",
    "print('Training Samples: ' + str(len(training_data)))\n",
    "print('Validation Samples: ' + str(len(validation_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "6\n8\n6\n9\n2\n------------------------\n11\n7\n1\n8\n4\n"
     ]
    }
   ],
   "source": [
    "# Shuffling the training and Validation Data\n",
    "import random\n",
    "random.shuffle(training_data)\n",
    "random.shuffle(validation_data)\n",
    "\n",
    "\n",
    "# Checking some samples\n",
    "for sample in training_data[:5]:\n",
    "    print(sample[1])\n",
    "\n",
    "print('------------------------')\n",
    "\n",
    "for sample in validation_data[:5]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",

=======
   "execution_count": 9,
>>>>>>> 45993eb5aa5e597f9d45cf4e107f7427ec971596:Dataset_Storing.ipynb
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(17706, 224, 224, 3)\n(5912, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Seperating the Image samples and Lables\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)\n",
    "\n",
    "\n",
    "X_valid = []\n",
    "y_valid = []\n",
    "\n",
    "for features,label in validation_data:\n",
    "    X_valid.append(features)\n",
    "    y_valid.append(label)\n",
    "\n",
    "\n",
    "X_train = np.array(X_train).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "X_valid = np.array(X_valid).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "# Normalize the pixel values in X_train & X_valid\n",
    "X_train = np.around(X_train/255, 3)\n",
    "X_valid = np.around(X_valid/255, 3)\n",
    "\n",
    "\n",
    "# Checking the shape of our output arrays\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",

=======
   "execution_count": 10,
>>>>>>> 45993eb5aa5e597f9d45cf4e107f7427ec971596:Dataset_Storing.ipynb
   "metadata": {},
   "outputs": [],
   "source": [
    "# save numpy array as hdf5 file\n",
    "import h5py \n",
    "  \n",
    "# Exporting training set\n",
    "hf = h5py.File(\"X_train.h5\", \"w\")\n",
    "hf.create_dataset('X_train', data=X_train)\n",
    "hf.close()\n",
    "\n",
    "hf = h5py.File(\"y_train.h5\", \"w\")\n",
    "hf.create_dataset('y_train', data=y_train)\n",
    "hf.close()\n",
    "\n",
    "\n",
    "#Exporting validation set\n",
    "hf = h5py.File(\"X_valid.h5\", \"w\")\n",
    "hf.create_dataset('X_valid', data=X_valid)\n",
    "hf.close()\n",
    "\n",
    "hf = h5py.File(\"y_valid.h5\", \"w\")\n",
    "hf.create_dataset('y_valid', data=y_valid)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving out training and validation sets into a pickle file\n",
    "# Pickle can't store very large files, and will likely give a Memory Error for large arrays\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Exporting training set\n",
    "pickle_out = open(\"y_train.pkl\",\"wb\")\n",
    "pickle.dump(y_train, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"X_train.pkl\",\"wb\")\n",
    "pickle.dump(X_train, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "#Exporting validation set\n",
    "pickle_out = open(\"y_valid.pkl\",\"wb\")\n",
    "pickle.dump(y_valid, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"X_valid.pkl\",\"wb\")\n",
    "pickle.dump(X_valid, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}